{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mental_Health_RoBERTa_Depression_Data_Augmented.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E8G-07rnBCC",
        "outputId": "ff338e16-69f0-4f10-bed0-d142383154ad"
      },
      "source": [
        "!pip install numpy==1.19.2\n",
        "!pip install tensorflow==2.4.1\n",
        "\n",
        "import tensorflow.keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, RNN, Dropout, Input, LeakyReLU, Bidirectional,Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "!pip install plot_keras_history\n",
        "from plot_keras_history import plot_history\n",
        "import pylab as pl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.19.2 in /usr/local/lib/python3.7/dist-packages (1.19.2)\n",
            "Requirement already satisfied: tensorflow==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.36.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.5.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.32.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.12.4)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.31.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.5.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
            "Requirement already satisfied: plot_keras_history in /usr/local/lib/python3.7/dist-packages (1.1.29)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from plot_keras_history) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from plot_keras_history) (3.2.2)\n",
            "Requirement already satisfied: sanitize-ml-labels in /usr/local/lib/python3.7/dist-packages (from plot_keras_history) (1.0.26)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from plot_keras_history) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->plot_keras_history) (1.19.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plot_keras_history) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plot_keras_history) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plot_keras_history) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->plot_keras_history) (1.3.1)\n",
            "Requirement already satisfied: compress-json in /usr/local/lib/python3.7/dist-packages (from sanitize-ml-labels->plot_keras_history) (1.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->plot_keras_history) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->plot_keras_history) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As7ral_ynGI_",
        "outputId": "bf7af50d-a858-485a-b9fb-c6ef83911ff4"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyFVWnLAnJwm"
      },
      "source": [
        "from transformers import DistilBertTokenizer, RobertaTokenizer \n",
        "import tqdm\n",
        "distil_bert = 'distilbert-base-uncased' # Pick any desired pre-trained model\n",
        "ro_bert_a = 'roberta-base'\n",
        "\n",
        "max_length = 128 #5000\n",
        "# Defining DistilBERT tokonizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(ro_bert_a, do_lower_case=True, add_special_tokens=True,\n",
        "                                                max_length=max_length, pad_to_max_length=True)\n",
        "\n",
        "def tokenize(sentences, tokenizer, pad_length=max_length, pad_to_max_length=True ):\n",
        "    if type(sentences) == str:\n",
        "        inputs = tokenizer.encode_plus(sentences, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        return np.asarray(inputs['input_ids'], dtype='int32'), np.asarray(inputs['attention_mask'], dtype='int32'), np.asarray(inputs['token_type_ids'], dtype='int32')\n",
        "        \n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "909Qd1UQnMK_",
        "outputId": "ed8eb7c0-82c6-4d90-c8de-7b9d36b81b23"
      },
      "source": [
        "inputs = tokenizer.tokenize(\"The capital of France is [MASK].\")\n",
        "print('INPUTS: ', inputs,'\\n')\n",
        "\n",
        "inputs = tokenizer.tokenize(\"This is a pretrained model.\")\n",
        "print('INPUTS: ', inputs,'\\n')\n",
        "\n",
        "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer)\n",
        "print('IDS: ', ids)\n",
        "print('MASKS: ', masks,\"\\n\")\n",
        "print('SEGMENTS: ', segments)\n",
        "\n",
        "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer, pad_to_max_length=False)\n",
        "print('IDS: ', ids)\n",
        "print('MASKS: ',masks)\n",
        "print('SEGMENTS: ', segments)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INPUTS:  ['The', 'Ġcapital', 'Ġof', 'ĠFrance', 'Ġis', 'Ġ[', 'MAS', 'K', '].'] \n",
            "\n",
            "INPUTS:  ['This', 'Ġis', 'Ġa', 'Ġpret', 'rained', 'Ġmodel', '.'] \n",
            "\n",
            "IDS:  [    0   133   812     9  1470    16   646 32804   530  8174     2     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1]\n",
            "MASKS:  [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
            "\n",
            "SEGMENTS:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "IDS:  [    0   133   812     9  1470    16   646 32804   530  8174     2]\n",
            "MASKS:  [1 1 1 1 1 1 1 1 1 1 1]\n",
            "SEGMENTS:  [0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYpk0TzgoMJd",
        "outputId": "29a2f4a6-8b6e-4623-c394-b9c90c606396"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('content')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at content; to attempt to forcibly remount, call drive.mount(\"content\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpW16rPPobp7"
      },
      "source": [
        "anxiety_path = '/content/content/MyDrive/Mental_Health_Data/anxiety_pre_features_tfidf_256.csv' \n",
        "autism_path = '/content/content/MyDrive/Mental_Health_Data/autism_pre_features_tfidf_256.csv'\n",
        "bipolar_path = '/content/content/MyDrive/Mental_Health_Data/bipolarreddit_pre_features_tfidf_256.csv'\n",
        "bpd_path = '/content/content/MyDrive/Mental_Health_Data/bpd_pre_features_tfidf_256.csv'\n",
        "schizo_path = '/content/content/MyDrive/Mental_Health_Data/schizophrenia_pre_features_tfidf_256.csv'\n",
        "dep_path = '/content/content/MyDrive/Mental_Health_Data/depression_pre_features_tfidf_256.csv'\n",
        "mental_path = '/content/content/MyDrive/Mental_Health_Data/mentalhealth_pre_features_tfidf_256.csv'\n",
        "\n",
        "filepaths = [anxiety_path, autism_path, bipolar_path, bpd_path, schizo_path, dep_path, mental_path]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZQEhDN2oett"
      },
      "source": [
        "def loadData(filename):\n",
        "\n",
        "  rows = []   \n",
        "\n",
        "  with open(filename, 'r') as csvfile: \n",
        "    # creating a csv reader object \n",
        "    reader = csv.reader(csvfile, delimiter=',') \n",
        "  \n",
        "    # extracting each data row one by one \n",
        "    for row in reader: \n",
        "      rows.append([row[0],row[3]])\n",
        "\n",
        "  return rows[1:len(rows)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "XDduaGShohkf",
        "outputId": "75f3f1e7-c0b4-4216-fb41-399c90c120f0"
      },
      "source": [
        "anxiety_data = loadData(anxiety_path)\n",
        "autism_data = loadData(autism_path)\n",
        "bipolar_data = loadData(bipolar_path)\n",
        "bpd_data = loadData(bpd_path)\n",
        "schizo_data = loadData(schizo_path)\n",
        "dep_data = loadData(dep_path)\n",
        "men_data = loadData(mental_path)\n",
        "\n",
        "\n",
        "print('Category, Instances')\n",
        "print(anxiety_data[0][0], len(anxiety_data))\n",
        "print(autism_data[0][0], len(autism_data))\n",
        "print(bipolar_data[0][0], len(bipolar_data))\n",
        "print(bpd_data[0][0], len(bpd_data))\n",
        "print(schizo_data[0][0], len(schizo_data))\n",
        "print(dep_data[0][0], len(dep_data))\n",
        "print(men_data[0][0], len(men_data))\n",
        "\n",
        "names = ['Anxiety', 'Autism', 'Bipolar', 'BPD', 'Schizophrnia', 'Depression', 'Control']\n",
        "sizes = [len(anxiety_data), len(autism_data), len(bipolar_data), len(bpd_data), len(schizo_data), len(dep_data), len(men_data) ]\n",
        "explode = (0,0,0,0,0,1,0)\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, explode=explode, labels=names, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category, Instances\n",
            "anxiety 19976\n",
            "autism 4576\n",
            "bipolarreddit 2720\n",
            "bpd 11007\n",
            "schizophrenia 4281\n",
            "depression 21209\n",
            "mentalhealth 18925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXiU1d3/8fd31mQmkz0hQICwCbIouIBaUVFb69KK1haXti6t1tZqbe3Tpr8uPt3tY+3q1tZaWq2orUtV3AU1igVcQEARlDUb2SaZJbPf5/fHPYGEJGRhkkmG87quXISZe86cAfLhzJlzvkeUUmiapmnDw5LuDmiaph1OdOhqmqYNIx26mqZpw0iHrqZp2jDSoatpmjaMdOhqmqYNIx26mqZpw0iHrqZp2jDSoatpmjaMdOhqmqYNIx26mqZpw0iHrqZp2jDSoatpmjaMdOhqmqYNIx26mqZpw8iW7g5oI1NF5YpcYGzyq+yA7wsBO2CbhbXpz7jHAHEgBrQDDcBeoD75a8fX7vJbFsWG+aVo2ogiuoj54a2icoUAU4D5wDFKqfnAMSJS2p/Hz45EGv7kLOnXtZih/D6wAXg3+euG8lsWNQy855o2OunQPcwkQ/Z44FyljNOAeSKW3MG2Nzvc7v1TVlnBIXarDlgFPAc8X37LovpDbE/TRiwduoeBisoVecAnVCJ+PiJni8VamKq2Z4fDTX/KKi1OVXuAwhwFP5f8eq38lkXRFLavaWmlQzdDVVSucCmlLsaIX4XFdoKIWIfieYYgdA/UAiwHlpXfsujNIXweTRsWOnQzzKTvPHG0ike+JTbnRWKxuob6+YYhdDvbCPwduL/8lkV7h+k5NS2ldOhmgIrKFW4jHv0CSl1vsTtnDedzD3PodogDTwG3lN+yaM0wP7emHRIduqPYxG8+7FaJ+A8sTvfXxWrLSUcf0hS6nb0E/Kz8lkUvp7EPmtZvOnRHoQnfWJ6l4rEfWrM9N4jNkZaw7TACQrfDauDn5bcsejrdHdG0g9GhO4pUVK5wxP3N37Vk5XzbYncOeplXKo2g0O3wJnBD+S2L3khVgyJSBvwOc6ldK+ZGjxuVUlsH2M6NwJ+VUu0DfFxAKZXW/1y11NHbgEeJ8df85SojFq6zeYp+MlICd4Q6Dni9urLqb9WVVf3dtNErERHgMeBlpdRUpdSxwPeAMYNo7kagxw83h2p1iTbyZFzoisgSEVEiMvMQ2nhaRPL7uOb/Dbb9gRhz8c+PKP/asjftheP+arFnpWx9bYYT4Apga3Vl1Q3VlVWHEmiLgZhS6u6OG5RSG4DXRORWEdkkIhtFZCmAiJwmIi+LyL9FZIuI/FNMNwDjgFUisip5bUBEbhORDcCJIvKtZHubkqNiLQNlXOgClwCvJX8dFKXUOUqp1j4uG9LQdU1faBl31e2/zCqftdGWW3LsUD5XBssDfg+8XV1ZdeIg25gDvNXD7RcC84CjgTOBW0VkbPK++Zij2lmYW6w/ppT6A1ALLFZKLU5e5wbWKKWOBkLAlcBC4ATgahGZP8g+ayNYRoWuiOQAJwNfAi5O3tbbyCNPRD4QkRnJ65aLyNXJ73eKSHHy+8+LyFoRWS8ifxIRq4jcAmQnb/uniPyk88hERH4uIt8Y7Osou+xXJxSddf1WR+nkSrE5HIP/E9GSjgKqqiurbj7EUW9nJwPLlVIJpdRe4BXMOV+AtUqpaqWUAawHKnppIwE80qm9x5RSQaVUAHgUWJSivmojSEaFLnA+8GzyA45mEekYIfY08mgDvg4sE5GLgQKl1F86NyYiRwJLk9fPw/whuUwpVQmElFLzlFKXAfcCX0w+xoIZ+PcPtPOu6QvtZV/49a3OcTNfs+YUTB3wq9cOxgr8L7CyurKqfACP2wwM9J1GpNP3CXqv5hdWSiUG2LY2ymVa6F4CPJj8/kH2TzH0OPJQSr2AucvpDuDLPbR3BuYP3DoRWZ/8/ZQDL1JK7cQM+fnAJ4B3lFLNA+l47sLPjMtf9MXVWeOP/LZYbfpDlaFzCrChurJqST+vXwk4ReSajhtE5CjMVQxLk+98SpLtru2jLT/g6eW+KmCJiLhExA1ckLxNyzAZU09XRAqB04G5IqIwRzYKWEEvI4/kqPRIzBqwBUD1gc0Cf1dKfa8fXbgH88ObMsyRb78VffL6M3KPX/KALafwkD9t1/qlEHisurLqLuDGgxXUUUopEbkA+J2IfBcIAzsx3znlYJanVMB3lFL1fXyA+2fgWRGp7TSv2/E8b4vIMvYH9z1KqXcG9/K0kSxj1ukmRyLHKqW+0um2VzB3LC1QSp2XvO124E2l1DIRuQmYAdwH/BY4USkVE5GdmEuPSoH/YE4vNCSD3aOU2iUiXqBUKRVLtuvAHDXbgen9edvomr7Q6p5zxnezpxz7Q4s9KytVfxbDaQSu0x2oKuCC8lsWDeidiaYNViZNL1yCuZ6ys0foZRVD8gO0LwM3KaWqgFeBH3S+Rin1XvK250XkXeAFzNMTwBy1vCsi/0xeG8WsCftwPwM3J3fBhf92HXHiz0Zr4GaIRcCa6sqqQS8x1LSByJiRbrolpyreBj6rlNp2sGtdMz5Wnrfwwked42Yef7DrRoMMGOl2aAHOS+VONk3rSSaNdNNGRGYBHwIv9RW47tmnzcg/6eIXMyFwM0wh8FJ1ZdWn0t0RLbPp0E0BpdR7SqkpSqmbDnZdztwz5ueduPRZx5gpM4arb9qAZGN+wLY03R3RMpcO3WGSM/fME/NO+OzjjuKJFenui3ZQVuA+PeLVhooO3WHgPnLRSXknfPYhe9GEienui9YvduBf1ZVVZ6S7I1rm0aE7xFzTF56Ye/wFf7MXlU9Id1+0AXEC/6murPpYujuiZRYdukPINX3h7Jx5Z//ROW7GEenuizYobmBFdWWVLjikpYwO3SHimr5wouuIk36fPeU4/QM7uuUBz1RXVumpIS0ldOgOAdf0hUXOCXN/7Z69+DSzBrY2ypUAj1ZXVulNLNoh06GbYq7pC932koqf5B5z7qfFYtWFazLHscDdfV6laX3QoZtCrukL7WLPui73uPMvEZvDme7+aCl3eXVl1XXp7oQ2uunQTa0LPcd+6kqrK68g3R3RhsxvqyurTk53J7TRS4duirimL5ydVTH/6qzxR+rCKZmtYw1vSbo7oo1OOnRTwDV9YZ41p/CbOUd9YrDncGmjSxnwx3R3QhuddOgeItf0hRaQK3IXfOYTFruzx+O1tYy0tLqy6oJ0d0IbfXToHrpT3XPOuNReMFbvODv83FldWaXn77UB0aF7CFzTF5Zb3YVXu6YtmJfuvmhpUQb8Lt2d0EYXHbqDZE4rcKXnmHPni9Wmj0k/fH2xurLqnHR3Qhs9MuZgyjRY4Bh7xAn2kgq9WuEQ1Pr2cuOKX9AUbEEQLp33Kb503Gf52ao7efHD1ditNiblj+e2cyrJy+p+kO5f3/wXD2x4CpTikqPP48vHfw6AX7x8F6u2r2F26XR+d973AXh08/O0tLfuuyaF7qiurJpxsAMuNa2DHukOgmv6Qhdwqefos+brbb6Hxmqx8sPFX2Pll+/jP1+4m7+//Rhbm3ayqOI4XvzSMl64ahlTCsu547/3d3vslsbtPLDhKZ764p947qp7eemjN9jhrcYXCbCpfhsvXLUMu9XG+40fEYpFeHjj01x+zIVD8TIqgGuHomEt8+jQHZxPumaeMs/qLhjb96X9F/c1Ur/8e9Te81Vq7/kavjf/0+V+39pH2fWr80i0t3V7bHTvduruu4nae75G7b1fJ/j+q/vua3zyVmrv/TreV/6+77bW1Q/SvjX9x4GNySlmbpl5kEaO08W0oknU+xs5dfICbBbzjdj8cbOp8zd2e+yHzbuYP/ZIsu1Z2Cw2Fk6Yx7NbX8WChZgRRylFKBbBbrHxp7UPcsUxn8FuHbI3dz+orqzqPhTXtAPo0B0g1/SFZeJwLXEdceL8lDdusVKw+EuM+/JdlH3h1/jfXkG0aTdgBnJoxztYc3teky92J8XnfotxX76T0s/+GO9Lf8EIB4g27MBiczLuqtuJ1m3DiASJB1qI1n6A64iRtax4T1sdm/duY/64WV1uf/jdp1k85YRu188onsza6nfxhtoIxcKs2v5fan0N5DhdnD71BD657EuU5hTicbpZX/cenzxi0VB2vwT49lA+gZYZ9JzuALimLxTgczmzTzvCYnfmpLp9W04htpxCACxOF/aiCST8zVA8Ee9Lf6Fg8ZU0PPKzHh9rLxy/vx1PERZXHon2NsRiw4hHUMpAGXEQC21V95N38mWp7v4hCUbb+cpjP+R/z7gej9O97/Y/rP4HVouVC2Z9vNtjphdX8LWFl3LZQzeRbc9iVuk0rGKOI7668FK+uvBSAP7nmV9x08lXsXzDU7y6Yx0zS6fwjZMuH4qX8a3qyqo7y29ZtHcoGtcygx7pDsw0rLbjnBPmzh7qJ4q37SW6dzvOcTNo3/ZfrJ4iHKVT+vXYSO0HqEQcW8FY7MUTsGbnUbfsG7imLSDurUMphbNs2hC/gv6LJeJc89gPWTLr45w949R9tz+88Rle+ugN/vipH9Lb3PnFR5/H01fcwyOX3U5elofJhV2XS2/auxWlFFMLJ/LUllXcteTH7PLWsqNlz1C8lBzgh0PRsJY5dOgOzLnuGYsmDMUotzMjGqLxsV9QeMbVYLHQ9sbD5C/6fL8eGw+00LTiNxSfcyOSHPUVnnkN4678I7kLLqS16j7yF32ettUP0fj4LfjXPzuUL6VPSin+55lfMb1oEtcs2H8I76rta7h7zQPc+5lfkm3vvYxtU9ALQI1vL89ufZUls87scv+vq/7Ktxd9mZgRx1AGABYRQvHIELwaAK6urqwaM1SNa6Ofnl7oJ9f0heXA0dmT588ZyudRiTiNj/0C96zTcM04iWjjTuJte6m993oAEv4m6pbdyNgv/gZrTtfNUEakncZ//5j8RV/AOb77Srb2bf/FUTYNFQsTa62jZEklex/6Ie7Zp2E5SLANpXU1G3lk83PMLJnCWX+7CoDvnnI1P3rxD0QTUS596FsAHDNuFr8869vU+5v4zrO/4h+fvRWAax7/Ia2hNmwWGz/7+De7LCt7dmsVR5XNoMxTDMCs0mmc+dfLObJ0KrNKh2yk7wCuAX46VE+gjW6ilEp3H0YF1/SFV2ZPPX6pZ97ZZw3VcyilaF7xGyxZHgrPvKbHa6rvuoqxl/8Wqyuv62MTMRr+dTPZUxeSe/z53dtOxNn78A8pvehm4t5afG8+SfE532Dvg9+nZMn3sGQNbvA+Oxxu+lNWafGgHpy5aoGK8lsWxdLdEW3k0SPdfnBNX1gELHJNO2FI53IjNe8R3LwKe0kFtX8zR7YFp3yR7KnH93x93TYC65+h6OwbCG55jfCezSRCfgKbXgSg+Jxv4hhjzgP7315BzpwzsNizsJdMRsUj1P71OrKnHjfowNV6NQ74DPBgujuijTx6pNsPrukLP+Mom/6F/I9d0n0IeZjTI91erS6/ZZE+vl3rRn+Q1gfX9IVu4KzsqcePS3dftFHlpOrKqmPS3Qlt5NGh27c5iMVhL5pwZLo7oo06PU/Ma4c1Hbp9Oy1r0tF5Q71MTMtIS6orq/TPmNaF/gdxEK7pCwuBGVmTjq5Id1+0UWkMoA+x1LrQoXtwR4nNYbUXjNNTC9pgfSbdHdBGFh26vUjWWTg9e8pxBWK1OdPdH23UurC6skrX/9T20aHbuzHABMe4GRPT3RFtVCsHFqS7E9rIoUO3d0cByuYprkh3R7RRb0gqp2ujkw7d3h1jKxiHxZGd1/elmnZQi9PdAW3k0KHbA9f0hQ5gWlb5rKJ090XLCPOqK6uy090JbWTQoduziYDYCssnpbsjWkawAz0X0NAOOzp0ezYFEFtuSUW6O6JljJPS3QFtZNCh27P5tvwypedztRTSxW80QIduN8n53OmOMdP0ya5aKo2sU0C1tNGh2914QGy5xYXp7oiWUYqqK6v6d8idltF06HZXDIjFla9XLmip1v0MJe2wo0O3uzJAWbM9ujC3lmpHpLsDWvrp0O1uEtBucbr1SFdLCUMZKpaI1wD6mBZNn5HWgwkWV54Sm0MvZtf6LZqIRQLRdq8vHPC2hn3epqC3pT7Q6N3dWuvb7q0uSBiJe1/Y9vpL6e6nln46dDtxTV9oA4rtxbrGjdaVoQwVioV9/kjQ2xr2t3hDbd6GYLO31tfQur1lT7Cp3QuQjbkRwkg+zAJYgW1AfXp6ro00OnS7KgCwuQtz090RbfjFOo1WvWGft7m91Vvvb/Tubqtt29FSHY0ZcQdmsApmsApmqMYxQ7Um+eXt9NX+wrbX9bSCto8O3a4KASVOl55ayEBKKdWeHK22hX3ellCbtzHY4q31NXh3ePcEG4ItYIaqAzNUFeZo1QY0A7VANdDI/lBtfWHb6/F0vB5tdNKh25UbEIs9S4fuKBVLxKOBaNDriwS9rSGft7nd660PNLXsbq317fBWR6KJWG+j1QRQhxmsnUerLejRqpZCOnS7ygYscyw7yI+EG3zisfklxx6w5NgDFo9TiVWfAJBmSikVioX9/mhybrU9OVr1m6PVvYFmgCzM0apKfgldR6s1QANmoOrRqjasdOh24iCWZydeWJn9eNmZeeHSA++PGhILJyzRsGGNtRu2eLthjweUMxE0nIZfZRk+la38uPDhFp9yW3ySI37Jsfokx+bDY/NbcuwB8diDFrcDHeC9Mker7V5/JOD1hpJzq4FG7562urbtLXvC0UTMiRmsFrqOVg26zq12hKoXCOrRqjYS6NDtZI7smGgjMcFhSFlP9zssyu6wJOy5JIDooJ9HKYgaEg0blljIsMXaDVus3bAngoYzEVBmgPtVtvLhxqfc4he3pY39Ae7HY/dbPHa/5NjbLS6HyOhabq2UIhTvmFsNeFtCrd7GYIu3ztfg3eGtDtYHmgz2z612jFY75lbbgQ8x51Yb6Dq3GkvLC9K0AdCh20mhBPzA2nHuLCdYhqz2ggg4rcrhtCYceSSAyKDbMhTKDHBrLJSwxkLKFg8ajnjADHDlV9nJADdH4H7ltrSJx+LHbfWJx+a35Nj84nH4LR57xOKyp+o1xo14bP+6Vb+3ud3r3Rto8u5urWvb7t0TjsSjDnofrdZhjlRr6TpaDejRqjba6dDtKgswxAyAUcEiSJZVObOscWe+PY4Z4MFBtWUoVMSQaDhhjSZH4PGgciQC+0bg2apjBN5mZDv9cXeuLz6peVtgWk1yJUBLrb/Bu9NbHazzN3aMVp10XwkQpOfRqlePVrVMp0O3KztgxAx1WP7gWwTJtipntjXuLKDnz5XaDYyHjZzWd6Mu44TXHSpbhVy/aHxxNT3PrXZ8aNUxWm1Bj1a1w5wO3a5igMQSvSTOIFX8zo/HKVgFbBZ485qcLve/vDPO+Q+2MznfnJu98Eg7PzrVSWPQ4IKHQrSGFT873cmSmea7//MfbOeuc7MY5xmeudyahET/qbKDK90uW2OOw3Xu09Gcr223OFxi8OqcRTtoXP4Xuq4EGPyEt6ZlOB26XUUAa9xIbegCrLrcRbGr95BcNNHGU5e6uty2fFOMa4+zc+GRds75ZztLZtp58oMY88ssQx647xi21gcd2a2v57hy2/IcBShVcMrzkfAP1icowuHomIBJFB7hWXLGT9+/7u7TW4e0Q5qWIXTodhUBLCNlesFuEdpjEImD1QJxQ/G7NVGevMTV94MHKKaUeh7n3key3NENuVlF0Rx7PpAPMHdNJHDFy8oxwbBndX6M1+6JKIutArMcpg5dTesHHbpdhQFLNMXTCyLwifvaEYGvHOvgmmMd3a55ozrB0XcHGOcRfv3xLGaXWrl0rp1LHw3x57ei/OrMLO5cF+ULR9lx2VPzOZ/XIPova3bDimyXZUdBVolyWLsslZu4LdZ61ZNx26yIPaenx+/Im+XH/KCsDNiSkk5pWobTodtVBLBE4oewCLcHr13pZnyuhYagwcfva2dmsYVTJu3/oz9mrJVdN+aQ4xCe3hZjyUMhtl2fQ16WsCI55eANKW55PcJjS11c/UQIb1hx04kOTpwwsL/CbYbF94Dd5V3ldrma853FWKX8wGuKGuL+LzwSS5zgteVbpPdVZE2FM+PJZx8zoE5o2mEsbavqRWSJiCgR6fMIExG5UURcnX7/tIjkD0G3ooB4wyqQykbH55p/zKVuCxfMtLG2JtHl/lynkOMwR6/nTLcTSyia2o0u1/z01QjfX+Rk+cYYJ0+08vcl2fzvK32v7zWU4mXD3vg1e96uBUVjfRdOLc/998TCSc1FWSVYpcuQOTuQiFz+j1DTH+5ROSe12vMtcvARdSxvSsd0Q4+bSTRN6y6dI91LgNeSv97cx7U3Avdj7kZCKXXOEPUpDKiGoPKnqsFgVGEo8DiFYFTx/EcJfnSqs8s19QGDMW5BRFhbk8BQUJS9P/C2NSeo9hmcVmFjQ32ELJsgAqFeZp4DivjjkrX3iWyX2pqfXZLIspYcrI/WmJE496lo85L3LUU5Yi/uzyrloMUZz3IVdhxRr0NX0/opLaErIjnAycBi4EngZhE5Dfi2Uuq85DW3A28CucA4YJWINCmlFovITuA4IAQ8DJRjrg/9qVLqoeT9y4GzMWudXgP8EpgG3KqUuruXrvkAo9ZvDG53QQ/2BhUXPNQOQNyAS+fY+eQ0G3e/ac5gXHucg3+/F+euN6PYLJBtEx68KBvpNMr8/soIPz/dDOpL5tpZ8mCIW16P8pPT9od3tSHty22uphfcLmddvrMYm2V8X31ThsGiV2INl64hv1jZSgeyJWRX/oxmEUvHtIKeXtC0fkrXSPd84Fml1FYRaRaRY3u7UCn1BxH5FrBYKdV0wN2fBGqVUucCiEhep/t2K6XmichvgWXAxzB3nG0CDha6fNhitCmlugTfYE0psLDh2u6fQ1173P4P076+wMHXF3T/cK3Dw5/dv1qh1G1h9ZfcAKw1bM032VyB1Z7svECeIx+Rfh95ceSGaOOVzxvuiritW2Gf/mgonB3u9Fs90tW0fkpX6F4C/D75/YPJ3z81iHY2AreJyK+Ap5RSVZ3ue6LTNTlKKT/gF5GIiOQrpXpa4uQDLO0x4u0xfG4HI+oEibChjGcka++jWa74przsorjbVgQM6ADN8TvjrVc9HrPMDdlLDmVKP5Q/zdlpkkSHrqb107CHrogUAqcDc0VEYU4LKOA/dE2BrB4e3kVypHwMcA7wMxF5SSn1k+TdHZ8yGXStKGPQ++v2Y05HWNsiyut2SNpDt9GQ8MPW7MZnXC7b7oKsEmW3jB1MO3nNieAXHolGPtZkK7QeZEVCf0SxGnZXSecj6vX0gqb1UzpGuhcB9ymlvtJxg4i8ghm4s0TEiVko5QzMD9rADEMP0GV6QUTGAS1KqftFpBX48qF07IkPYurTM+wNQFZDUDWM8zDpUNobrM2GtW253dX6ao4rx5vvKMQiEwbbljNkRD/zaKTt7F22YqfY3ako5bM7d2qLxWLtHLqld1y7Uq67+3RdU0HT+pCO0L0E+NUBtz0CXIz5odgmYAfwTqf7/ww8KyK1SqnFnW6fC9wqIgZm3YSvpqB/NcDs7V6jZl6Z9fgUtLdPOK445W9BIgnzQ7WLjrTx48VZxJVSK3E0/svpDj+3Pjym4Y22PJFQniXLy7grxpE1PovgtiC1f69FbMKEayfgLHOSCCbYfeduKm6qQCxd01TihnH2s9Gmz2y0FHqwl6Syblp94ewA0Dl0bcnfN6buWTQtM4lSenDS2adn2M8ALptfZmn/8eKs61LZtlKKYAxyHEJTTMWOvTekJp1f0tZ2TH6e4bQ6ABKhBNZsKwC+d3y0vNRCxbcr2P3H3Yy9bCzRpii+t3yMvWQsdQ/W4TnaQ86RXT+oW/h6tOHzVUbeGGVzdu/FoXt23ndqHPmTDlwdMfe6u0/fNBTPp2mZRO9I624PoDbsNZqjCRVxWCVlwbVDWQPLs1wtK3NcWfXZ9uIG5w6LrTS7xOW07rumI3ABjIixv7KvFYyogRE1EKsQaYgQa4l1CdwjNsearngmkT0tZisdqn0vhgKLZ2xPH96VYb5L0TTtIHTodlcDiKFQjUFVNz5XKg6lsdcMW9PDTndwrSc7P5hrz1OKnI9u/ohoQ5TCMwpxTe1evKb5xWaanmtCJRSTvzMZgJJzS6j+czUWh4Xya8qpf7CeMRean1+V1sTbrnw0xrEBe/FQ/5XWuMtbbVZHT7sB9QoGTesHHboHeOKDWPDTM+yNgKvaZ9SMz7VUDOTxYUMl/mPJbng8yxV/Pz+rOJFtK6bT/KcITPvpNHM+9o+7CVeHySrvulCj6Mwiis4sovWNVhqfbKT86nKyJ2Uz9UdTAQh+EMSWb8PVlgipW3dYs6OWvEmlY4blb7OmcE4byepjB9ArGDStH3To9mwLsGBLk7FnYbdyMN3VKWl/0JLd9Jzb7ajJd5bQj2VdVrcV95FuAhsD3UK3Q97CPGr/UdvlNqUUTY81qK+VlzRvuL2x6KaSMqmNxbjf6+XGkoPu9k2JtsIZll4WnOmRrqb1gw7dnn0ALFq5I77j80fZDaul+3G7ySLfba/luDy+PEcBlr53g8V9ccQqWN1WjKhBYHOA4nOKu1wTqY/gLDOnkf0b/DjGdNqpZhiq7K4m/xnN2TmXq6zi65XCgjntG1ZdC+QMGc+Egl7u0aGraf2gQ7dnuwC8YaL1AbV7fK5UxJRSzyWLfL+bm10UzbHtK/LdX/G2ONV/qUYZChTkLcgjd14uex/dS/bkbHLn59LyUguBzYF94Vx+tTnUnr820vC5lxK5P90dyP3SBHPZ7uUFhVxbXY1d4NZx41L8R9Bdo7MoaLdn91hbFz29oGn9opeM9eDTM+wC/BYIn3Cie/aaWYXHJIt8p+yI8v6q2BpvueqpmGNmL4XEh9NbZafsaZu5tLeNGhuvu/v0o4a1Q5o2CumRbg+e+CCmzp5hf7vFar3q7ztVkWOxe+iHkQcoro/7vvhozFjQais8WCHx4dRSOEtZe79bTy9oWj+krYj5SLfV4fhwu92mGr3Gmnggvne4njfbn/bTHy0AACAASURBVAhf+fdQ8+/vVZ4T2vouJD6cErmTPAe5u+iOa1ceJJM1TQM90u1Vo836FrANaIjURN63zbAN6ZylNWokznsq0rxki7XILfaiVG7bTQWfzR1xZOX29iEamP+BlwJ1w9QlTRuV9Ei3F753fBHgLaAosCkwZDutlGFwykvhvbffFktc9oG91C2WETla3Fkwq7kfl+kpBk3rgx7pHtwaYGF4T3hvrDW2255v73eR8P6Y80608fIXjJxJiaEdRadCU8Gs/hxLP+Jfh6almw7dg9uCeVilo31r+5t5C/JSErrlO+Leq/4Ts805xELiwymSP8XVjyIUeqSraX0YMT/xIpIQkfUiskFE3haRk5K3jxORfx9Cu4M+2df3ji8MrAJK2ta1vWfEjNBg2wLIb0oEr/9TyHvrclUwJ2Q/2IdSI0pIHHFHdmF/TqjQoatpfRhJI92QUmoegIichXmQ5KlKqVrMwudDTsxD0USpLtu7XgM+qWIqEd4Tfts1xfWxgbbrDBrRzz4WaTtrd+oKiQ+nXXlHtIhY+nOWmp5e0LQ+jJiR7gFyAS+AiFSIyKbk91eIyH9E5GUR2SYi+45uF5Fvicim5NeNBzYoIjki8lJyFL1RRM7v1P4HIvIPzNKEBy7+rwU+Agrb/tu2Vhn9329riRnGOU+GG+78fdz66T32EmcqTrpMg71Fs9v7eake6WpaH0bSSDdbRNZjno02FvMctZ4sAOYA7cA6EVmBecbalcBCzFIEa0TkFaVU59MnwsAFSimfiBQD/xWRjsMrpwOXK6X+e+CT+d7xqdz5uSuAG6IN0V3Rhuh7zjLnnL5ezIlVkYbLXie/dIBHm49E7fnTsvpZVFiHrqb1YSSFbufphROBf4hIT+H2glKqOXndo8DJmKH7mFIq2On2RXQ98keAX4jIKZiHU45n/9vhXT0FbicbgVbA5XvL90bJuSW9hu4Rm2NNVz2dcE0Z5NHmnX2/ro5XggEKrVaemDwFgD80NbLSH0AEiqxWfjF2LKW2rjvWamIxbqipxgDiSnFZQQEX5xcQNQy+XlNDfTzGJfkFXFJgLru9ub6OpfkFzMrqXu0sjkXZ3KX9PXFYTy9oWh9G5PSCUuoNzBq0PdUqPLBYRH+LR1yWbO/YZLjvZf+Jw8GDPdD3ji+OeUR8Sfu29tpoY/SDA68p2xNvq/xDqO1nT0jxlLite2XyQbggL48/l3ed7biqoJDHJ0/msYrJnJqTw51N3ZfPlthsLJ84iccqJvPgpAruaW6mIR7jtfYgx7iyebxiMk/42gDYEg6TgB4DF2C3p8Jrtdj6uw9Zj3Q1rQ8jMnRFZCbm0ew9Lcj/uIgUikg2sAR4HagCloiIS0TcwAXJ2zrLAxqUUjERWQwDPun3v5hTFFmtr7euVMlKQR5vov3ae0LNv71P5R0TtOcNsM2DOs7lIs/a9a8ox7p/70TIUD3OXDhEcFjMx8WUomMS2oYQMhRxpfb9T/XHpiZuKC7uoRVTXeEc/wC6XHDHtSsdfV+maYevkTS90DGnC+ZUwOVKqUQPnz2txTw9uBy4Xyn1JoCILEveB3DPAfO5AP8EnhSRjcCbmGtw+833ji+YOz/3EeCy0M7QLtkRXr90LeXnbrcWZYndNZzztr9rbOQJXxs5FgvLJvS8dLguFuOr1dXsjkX5dkkppTY7hW4bT/p8XLx7F1cVFrIy4OfILGe36YnO/AVH2AaYomMwz5nTNK0Ho6q0o4hcARynlPp6Op4/d35uFkr9yhVhzBy/bc5v3GNm2Yd4RUJNLMpXq6v3zel29ufmZiLK4Pri3k+MaIjHuL6mhjvGl1Ns2/9/bEwprqnew+3jx3N7UxN1sTifzsvl9Jz9y4cNBS8u+k3IZnNmD6DLC667+/R1A7heyzC3LT2vFHDf9NBTO9Ldl5FoJI10RzzfO77w5KmeF4rb+GkoHl+/2RpumZedvShd/TkvN5drq/ccNHRLbXamOZy8FWrnLE/uvtsfbPXy6dxcNoTC5Fis3DaulCv37O4SunWucW02m3OgUyZ6XjfD3bb0PAcwGZjS6WuqUmoKMFlEcoAXgE+kr5cj16gKXaXUMmBZOvtQ0cCzwEmAe3mrd/cMp3N+tsUybAXGd0ajVDjMN/wrA36mOLov5qqPxci3WsmyWGhLJHg71M7lhfsLhLUlErwcCPCX8gmsCgT2HfkTOeBdT03h7FbMufCB0CsYMsBtS88roVOgAlOSoToVGCfS/QirA970pbROSSYZVaE7Eqzy++OLPZ77ge/6DaP1lWDg+U96ci8ciuf6dm0Na9vbaU0kWPzRh3y9qJhXgwF2RKNYEMbZbdw8xhxYbgqHeKi1lZ+WjWV7NMr/NTQgAkrBlYVFHOHcvzrhruYmvlJUhEWEk91ulrd6OX+nj6X5XU8f8hbM7O0QyoPRI91R4Lal59mBCpKB2vGllJoKTEmOVrsY4ExabyeMHPZG1ZzuSLHY4xHgBmAWUFdZUvq5iQ7HkWnuVso9d9L/+e0O90BrRNxx3d2np2XOXevqtqXnFdPzFMBUYHxPo9UUK7rpoadahvg5Rh090h2EVX6/WuzxPAj8DMi6p6X5yf9XOmZC1jBOMwyFMz/6ELfFikVAic244bSugbtu24u8sP5BFJBlz2bpohspL5qKP9TKX56/mVAkwKlzlsy/LrmZUET+A3w1WT9DS7HkaHUSnaYA6DQNICLd/sMc5p3obkCH7gF06A7SKr9/72KP5x/A1U2JxI4Vft8Tn8nLvzTd/TpUyyZMoMBm450xJ9d6zWV5+xR5xnLjp3+Ly+lh8+41LH/1N/zPBXfw1ocrOfnI85g3eRG/feKbs+G3iMingHd04B6a25aeV0j3KYApwDTM0Wq3ovcjqMRHzztuDnM6dA/N68AxwJyXAoFtc7Ky3prhzDo23Z1KhebCIxMHvvecUjZ73/eTx8yiNdAIgNViIxqPEDdi2K12h4jYgBuBTw1bh0ep25aeZ2P/aPXAaYApItLtg8wRFKp9GchSw8OGDt1DsMrvNxZ7PH8Hfg64/9rS8tyPSsdMzrFaC9Pdt8EQEb5cvQcBZua/X3z6mHm9Xrt6yzPMmrgAgOOmnc6ylb/g9fdX8OkFX1J3PP3drwH3KaX6W50so9229Lx8zNFqTx9aTRjho9VDoUe6PdChe4hW+f2tiz2evwDfChjGzn+3tT32xYKCqyyj8Kfm/gkTGWO3s1vZo1dtW+meWDqbaeOO6nbd1pp3eGPLM3zz/N8BkO3M4atn/wKA9ojfZRHL+YYyzheRvwAFwG3JehoZ6bal51npPlrtCNWpPY1WIWOC9WB06PZAh25qbABeBj62NtS+Z4rD8cwpOTnnpLlPAzbGbi4Q8xXPbT7aYxu7s3FLt9Ctaf6IB169ja+e/UtysrpnyTNv3cfM8mPveW/PukswC8D/G3gUOGvIX8AQu23pednAuXRdu9oxWu32s3QYhGpfdOj2YEQWvBltVvn9CngI85Pa4gfbWtdtDocPVipyxGk3DIJGAoA9udOiW6rfZFxBRZdrWvx7+cvz/8sXF3+PMfndl2E2tFXTGmzia+fcshNwYZbQVGTA3N7s8WUTXv5g+ynAv4BfAdcAZ4rI5J4CVwN06PZI/2NJkVV+f3Cxx/M74EeA567mpucrS0sLyu2OGenuW380x+PcUFsDQEvdX8oXzjibWRMXUPXekwAsmvUpnnn7PoJhHw+99nsALGLlu5+5a18bT669l08tuArMDRLLgceBSsw/k1Fr9viyPODmHU0tllOPmKxED2H7S28C6IHeHJFiiz2eI4HvAPVui8X4XknpFYU227h096u/omJLvLrot1gslm4f7gzA1667+/S7+r5sdJg9viwbuAPY/YUT5/+P3WpNSb3kw8DJNz301Ovp7sRIo6cXUmyV3/8+cC8wPmgYxh3NTcvbDaMt3f3qr52501sOMXAh8+ovhDGnSiyxRGLQp0sfhrzp7sBIpEN3aLyG+dZ6Ul08HlzW0vJATKlIujvVH/VFsw96ikY/ZVT9hc019QrzuCZHNK5DdwD0brQe6NAdAskP1h4HVgMTNkXCDf/wtvwjYhihNHetT8H86f08g/KgMip0k7zo0B0oPdLtgQ7dIbLK7zeAvwHbgAlvhUK197S0/C1kGCP2hzahRNncZf09hPJgMm16AcxRmyMcj4/Yv7+RRCnVftNDT42Kd3fDTYfuEFrl90eA3wHvA5M2R8JNdzU33Rs0jNY0d61He3ImtVqtAz2dp0eZONJtBhzhmA7dftKj3F7o0B1iq/z+EPBH4G2g4sNotPX3TY33+hKJpjR3rZu6otm+FDWViSPdZsAWisZSMeed8USkp0NlNXToDovkiPduzA/YKqpjseBvmhr/5k3E69PctS7aCmYc6qqFDtl3XLsyt+/LRhU/QHs0qke6/bMt3R0YqXToDpNVfn8McynZi0BFQzweubWhcVldLPZhmru2j3jGp7JQT6ZNMQQAwx/WodtPm9LdgZFKh+4wWuX3JzCPgn8CmNRqJNTPG/Y+sD4Uqkr3JpW6rDF+uy0rlYv+MzF08YXDOnT7Z3O6OzBS6dAdZslVDY9grmwYZ0Dun1uaV/7H53swnWt5qwtnp/qDj0yb1w0A4gtF2pVSRro7MwrokW4vdOimwSq/X63y+1dh1uG1AmOfD/g/+H1T493N8XhNOvrkLUj5EW+ZONK1AMQShv4w7SCUUlH0nG6vdOim0Sq/fxvwv8BOoGJ7NBr4ScPeezeGQquHe7rByJ040KPW+5JRobu5pj4KRAFrLJHQoXtwW2966Kl4ujsxUunQHQARSYjIehHZICJvi8hJydsrRCSUvO89EblbRCydbn9HRN4XkbUickXnNlf5/S3ArZg72CbElMq5q6X5hX+2epf5EonG4XhdLfa8kMOZk+rQzbTpBdBbgftFRDamuw8jmQ7dgQkppeYppY4Gvgf8stN9Hyml5gFHYR7NvqTT7fOVUkcCFwM3isiVnRtd5ffHV/n9jwO3YJbbnLC6vX3PD/fW3/3f9uCLcaViQ/midhfMGoo1lRk10k3yAo6I3pXWl7fS3YGRTIfu4OXSw64bpVQcs+bCtB7u2w58C7ihpwaTFcq+j3kKxcSYUgX/8Hpf/3Vjw+17otEtKex7F02FsxJD0Gwmhm4LOnT7Y2W6OzCS6dAdmOzkFMIW4B7gpwdeICIu4Aygt7dYbwMze3uCVX6/f5Xffx/wE8xdUBW7Y7HoLxsbHnqkrfWBgJFI+fbKWF5FTqrbJDOnF5rQW4EPylCqDVif7n6MZDp0B6ZjemEm8EngH51OEZgqIusxj2VfoZR6ppc2+nXqwCq/fzvwM2AZ5uGO418KBD66ub7+zteCgWfbDSMlW3aDlqyYI6tgKE4vLr3j2pWZdsJCM2Brj8Z06PZCKbXqpoee0icjHIQ+rmeQlFJviEgxUJK8qWNOty/zMQvg9GmV3x8HXl7s8awHLgJODikVfqC1de2/2trWfcqTe9RCl+tkj9U66Mpgu/JnNIvIUEwFOIBCzKDKFEHAaI9G9eqFXlgtlqfT3YeRTofuIInITMw1ts2YhzD25zEVwK8xC+D02yq/vxW4Z7HHsxI4D5gfUyr2qK/t3cd9bRvO8nhmnuxyLyqw2cYOpF2AhsLZ4YE+ZgDGkFmhGwCU3gp8UCvS3YGRTofuwGQnpxDAnCa4XCmV6OOcwqki8g7myah+4A9KqWWDefLklMMfFns85ZhHmn/MAOMZv3/bM37/+6e63VNOdrsXjrXZp1lE+jV1FMqflp2KquW9KAPeG7rmh10AoC2ktwL3JG4Ym7/7r6dr092PkU6H7gAopXqswqWU2gnM6eX2lB8/vsrvrwb+utjjeRI4EzgdsLwSDNa9EgwuL7Jas0/PyZk1Oyt7bonVOqm3/xSi2Ay7q7g41f3rJNNWMAQACUaiYUOphEUkVVXZMoJF5JF092E00KE7iq3y+xuABxZ7PE8DizDDt7Q5kYj/q61t47/a2t6aYLfnnubOmTMzyzm3wGrrEoK7c6e0WCzWoQzdTFvBEGTfVuBEwGmzHfKGktb2EMvXrMcfiSLACVMmsuiIyTy3aStrduwmx2m+Dzl77gyOHFva7fGhaIyH33yX+jY/Anzu+KOpKC7gqQ3v80F9I+Pyc7lkoflRw1u7qglGYpxyxORD7XY3SillEVmW8oYzkA7dDJCc831yscezApgMHA+cAmTvicWi97V61wKrpzuchcdkZ0+d4HAeMcZun1xfODsA6JFuP22uqY/NHl8WAmyxeGpC1yLCp+bNorwgj3Aszu9eeI3pY8y/klOmT+a0mVMP+vjH39nMzLISLj/pWOIJg1giQSgao6bVx01nncLD696lrtVHcY6bdTuqufqUBYfa5R7FEok133vk2R1D0niG0aGbQZIVzD4CPlrs8TwCTAdOBBYC1m3RiNoWjWyJ2nNCQdeYuor6jzaWiXtiSe64CbmuovFZDlehRSypXEaYUaGbZG4FTlH9hdzsLHKzswDIstsYk5uDL9S/zzZD0Rjbm1q4eMHRANisFmxWC+FYnIRhoJQilkhgtVh4+YPtnDy9AmtK/3r3s1ostw9JwxlIh26GShZNfw94b7HH80/MEfAM4BhDbLmG2IMfte7J+qh1z3bgXSBmtdgsY/In5Jfkji8uyCkpynUVFrucnkKHLSvHbnO4bRZ7dh8fGu5jKCNmEYt9qF5fGnmB8ZEhqL/QEmynprWNiUX57Gjy8vqHu3hrVw3lBXl8at4sXA57t+tznA4eWvcuta0+ygvyOH/+LLLsNo4cW8pvX3iNaaVFZNlt7G5p5eOzp6e6ywAkDMNvtVj+PSSNZyBJd/FsbfgtLJmS2+4uGw9UYH4AWIG57C2BuSpDgHYgDMSSX4aIRdxOj9Pl9DizHC4ngGEYhqEMpVTCMJShDCNh+EOteeFY++qNO1f/dfhf3dCaPb7sS8Cxp8+cOruiuOCUVLUbicW58+U3OPPIacwtH4s/HMHtcIDAc5s+wBeKsDQ5ou2wp6WVP760mutOP5FJRQU8/s5msmw2Pjl3RpfrHl73LidNm0SNt40P6psYl+/hzFmpC+BILH7P/3v02atT1mCG0yPdw9Caxu0+wIe5SeOZuRUnCeAGijDneMdgBnEJkJf81aqUYQTCbSoQbutoqmPYq9gf1oIZ1nuH5cUMvybAEYqlbldawjD4++q3OGbieOaWm0utPVn7F/ItnDKRv1at6/a4vOws8rKzmFRUAMBR5WNZuaXr6U813jZAUeJx8/S7W7jm1IU8uHYDjf4gJR53SvrvtNv+kJKGDhM6dDU27lytMJdDBYBdB96fDGU75lpjJ+amEAUYyV87vo8DoY07V2dyLdUWwJqqrcBKKR5e9y5jcnM4dcaUfbf7QuF9c72bqusZm+fp9tjc7CzyXVk0+AKU5uawbW8TY3K7Xvfspq1cdNxcDEPR8a7WIhBLpKbGUTSe2PS9R57RpRwHQIfuAInI94FLMd+KG8BXlFJrerjuCuA4pdTXe7jvaeBSpVRrivr0MvBtpdSbh9BGr31KhnJHEe/DXRAwgpHU7Erb2eTlrV01jM3z8JvnqwBzedg7u2upbfUhQIE7m4uOnQtAWyjMv9a9y5eTqxCWzJ/NA2vWkzAMCt2uLlMQm2rqKS/IIy8Z3uPyc/n1c68yNs/DuPzUHNaslPpRSho6jOg53QEQkROB3wCnKaUiydoLDqVUt104BwvdIejXy/QRuiJiS5ad1A7B7PFlRwDfKcvNaT/nqJnXp7s/6RSKxrb94LHnjkh3P0YbXWVsYMYCTSp5gKRSqkkpVSsix4vI6uSJEmtFpOM93jgReVZEtonI/3U0IiI7RaRYRK5NlopcLyI7RGRV8v5LRGSjiGwSkV91elxARH4rIptF5CURKenUt88mn3uriCxKXn+FiDwhIiuBl5K/f/RgfUp+/7iIvJV8nmuG6g9zlAoAtOqtwMQSicp092E00qE7MM8DE5LBdqeInCoiDuAh4BvJEyXOBELJ6+cBS4G5wFIRmdC5MaXU3cnKZMcD1cBvRGQc8CvM3WXzgONFpOMUCjfwplJqNvAKcHOn5mxKqQXAjQfcfgxwkVLq1P70KekqpdSxwHHADSIy6CpmGSgASDgWjyYMY0hP9BjJQtHYlh8/8eKj6e7HaKRDdwCUUgHgWOAaoBEzbL8C1Cml1iWv8XV6G/+SUqpNKRXGXDM7qZemfw+sVEo9iRnALyulGpPt/BNzdxmYc8gPJb+/Hzi5UxsdPwBvYa486PCCUqql0+/706cbRGQD8F9gAuYmC80UJLlqI5YwDtvRbjSR+E66+zBa6Q/SBkgplcA8Tufl5AF81x3k8kin7xP08OednPudBAxm7rfzhHzHcx34PAfunDpon0TkNMzR+olKqfbkfHHWIPqWkTbX1Cdmjy8LAvZYIhHIstsK0t2n4dYejW36yRMvPpnufoxWeqQ7ACIyQ0Q6j/rmYa51HSsixyev8YhIv/4zE5FjgW8Dn1dKGcmb1wKnJud8rcAlmFMJYP59XZT8/lLgtUN6QT3LA7zJwJ0JnDAEzzHadZwKfNgVM1dKEY0nvpHufoxmeqQ7MDnAH0UkH3NN6oeYUw1/S96ejTmfe2Y/2/s65ukKq5Lba99USn1ZRCqBVZhvY1copf6TvD4ILBCRHwANmHOzqfYscK2IvA98gDnFoHXlBSYdjgdUettDK37+1Ep98OQh0EvGRhERCSilhuIQSW0AZo8vuxw44bQZU2ZOKSk8Ld39GS6RWNz/UWPLtL9WrW1Id19GMz29oGkD1ww4wincCjwa7PUHKnXgHjoduqOIHuWOGF7AcjidCtwSbF/34nsf3pXufmQCHbqaNnABwAikaCvwSBdLJMKN/uDFm2vq9VxkCujQ1bSBCwLKH44cFqsX9voCt/z5lTXb092PTKFDV9MGztwK3J75W4Eb/cF1z2/e9pN09yOT6NDVtIELAJZYIhGPG0akz6tHqUA40rxhT+1n9LRCaunQ1bSBa0/+KrFE6o/tGQniCSO2pb7xqmc2frAn3X3JNDp0NW2ANtfUG5gnb9hjQ3BWWroppdT7dQ23Ll+z/onerhGRRLI63uZkdb2bRGTE5ImIfDq5yWjE0TvSNG1wvIBnKA6oTLePGlueWbez+uY+LgslK+QhIqXAA0AuXSvcDYqIWJM1TgZNKfUE0Ot/Guk0Yv5n0rRRxgs4ovF4Rq1gqGvzb351645LN9fU97vgvVKqAXM7/NfFZBWRW0VknYi8KyJfAbOYkoi8KiIrROQDEbm7Y3ScrBV9W7K63Yki8vlkfej1IvKnZJtWEVmWrDO9UUS+mXzsDSLyXvK5HkzedoWI3J78vkJEVibvf0lEJiZvXyYif0jWwt4uIhf18PJSToeupg1OC+AIxzKn/sJeX2BH1dYd526uqW/r++qulFLbMc/OKwW+BLQppY7HLFV6tYhMTl66ALgemAVMBS5M3u4G1iRrUjdj1hX5WHI0nQAuwywwNV4pNUcpNRez5glAJTBfKXUUcG0P3fsj8Pfk/f8EOh+kORazROp5wC0Dfd2DoUNX0wYn5acCp1ODL7Bn5fsfXbRm++5uB5MOwieAL4rIemAN5inTHdX51iqltienD5azvyZ0Angk+f0ZmHWr1yXbOAOYAmwHpojIH0Xkk5jz6gDvAv8Ukc9jFqI60ImY0x8A99G1DvXjSilDKfUe5inYQ07P6Wra4LQBZMJW4CZ/sGbllo+Wvrlzz9uDbUNEpmAGZwNmdbzrlVLPHXDNaXStAU2n34c7zeMK5sj0ez08z9HAWZgj2s8BVwHnYhb6/xTwfRGZO4Cud17yJwN43KDpka6mDU4AUIHw6N4K3Bxor1u55aPL1u3Y88Zg20ie1Xc3cLsyyxY+B3xVROzJ+48QEXfy8gUiMjk5l7uUnmtCvwRclPyADhEpFJFJyTP8LEqpR4AfAMck25mglFoFfBezHvSBNUpWAxcnv78MqBrsa00FPdLVtMEJAMoXHr270lqC7fUrt3z4+TXbd7/S99XdZCff+tsx39Lfh3lSNsA9mEdGvS1moehGoOOcv3XA7cA0zJrRjx3YsFLqvWTN6OeToRrDPKElBPyt09K072HOI98vInmYI9U/KKVak/WpO1yffNz/JPty5SBeb8roerqaNgizx5eVAr+0WqTmiyce88MDfshHvAZfYE/Vtp1Xr/5w53N9X50ayemFbyulzhuu5xyJ9EhX0wYnAEjCUEbCMEI2qzU73R3qrw8bmjdVbd3xjU019foEiDTQoatpgxPCPJ3ZEk0YgdEQuoahEu/srl29obquEhj0HO5gKaVexjzU9bCmQ1fTBmFzTb2aPb6sjY6twA57Sbr7dDDReCL02oc7n97Z5K3cXFP/Ybr7czjToatpg+cFCiKJkb1BIhCOeFdu+eifTYH2n2yuqW9Md38Odzp0NW3wvMCYyAjdlaaUYndL6werP9x1TygWv3NzTX1734/ShpoOXU0bvOQBlSOv/kIkFvf/d/vu/37U2HIP8MjmmvpDKiCjpY4OXU0bvGbAPtK2Atd427a+unXHqlAsfiewURchH1l06Gra4PkA2iMjI3Sj8Xhw7Y7qNVv3Nj0MLN9cU+/r80HasNOhq2mDZ24FTvOpwEopVe1t27L6w12rg9HYXcDbenQ7cunQ1bTBM7cCh9K3Fbgl2L7zjY92v7vXF3gBuH9zTX1ruvqi9Y8OXU0bvCAgbaFwu1JKyTDuBfaHI3Xv7K7d+GFD8ybMGrHv6NHt6KBDV9MGLwBYFKi4YbTbrVZ3n484RMFItGFDdd27W+oat2PWn31lc019xp5InIl06Gra4EUwK2BZo/FEYKhCVymlmoPtH7xX27Djw4bmWuBZ4IXBnPCgpZ8OXU0bpC5bgc2j2FN66znDiAAAAbFJREFU8kA0nghUe9veXb+7dk+rOW+8Cnhmc019SyqfRxteOnQ17dC0ACWpOhVYKYU/HNm1dW/Tls01e+sTSrUCTwNr9Mg2M+jQ1bRD0wKMP5StwAnDiLW2h7fXtvo+3FLf2OoPR2LAJuB54P2BnMyrjXw6dDXt0HScCjygrcDReNzfHGjfuqu5ddfWvU3+uGEkgDDmFMJrm2vq64eis1r66dDVtEPTDNjbD7IVOJ5IhAKRaJ0vFKlrDrbX13jbgg3+oIF5KGMD5hlem4BdukZC5tOhq2mHxg8ofyjcForGmiLxuC8ci/vao7HWlmB7Q02rr7U50K4AJ2bRc4BtmEG7BWjU62sPLzp0Ne3QBADZ1tDs3dbQ/DBmuFowR7EdhzJuS37VAfWba+pD6eqsln46dDXt0OwFqjHX7DYmf18P1AJ79cYF7UD6NGBN07RhZOn7Ek3TNC1VdOhqmqYNIx26mqZpw0iHrqZp2jDSoatpmjaMdOhqmqYNIx26mqZpw0iHrqZp2jDSoatpmjaMdOhqmqYNIx26mqZpw0iHrqZp2jDSoatpmjaMdOhqmqYNo/8PoR3G/bLTHz0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcT8d0nKSPQS",
        "outputId": "48d55784-e9a9-46a2-9a79-df7121534c80"
      },
      "source": [
        "import sys\n",
        "# insert at 1, 0 is the script path (or '' in REPL)\n",
        "sys.path.insert(1, '/content/content/MyDrive/Mental_Health_Data')\n",
        "import data_augmentation_methods as eda "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar1Wpp7ISKzZ"
      },
      "source": [
        "for i in range(len(anxiety_data)):\n",
        "  sentence = anxiety_data[0][1]\n",
        "  label = anxiety_data[0][0]\n",
        "  augmented_sentences = eda.eda(sentence)\n",
        "  for j in range(len(augmented_sentences)):\n",
        "    anxiety_data.append([label, augmented_sentences[j]])\n",
        "\n",
        "for i in range(len(autism_data)):\n",
        "  sentence = autism_data[0][1]\n",
        "  label = autism_data[0][0]\n",
        "  augmented_sentences = eda.eda(sentence)\n",
        "  for j in range(len(augmented_sentences)):\n",
        "    autism_data.append([label, augmented_sentences[j]])\n",
        "\n",
        "for i in range(len(bipolar_data)):\n",
        "  sentence = bipolar_data[0][1]\n",
        "  label = bipolar_data[0][0]\n",
        "  augmented_sentences = eda.eda(sentence)\n",
        "  for j in range(len(augmented_sentences)):\n",
        "    bipolar_data.append([label, augmented_sentences[j]])\n",
        "\n",
        "for i in range(len(bpd_data)):\n",
        "  sentence = bpd_data[0][1]\n",
        "  label = bpd_data[0][0]\n",
        "  augmented_sentences = eda.eda(sentence)\n",
        "  for j in range(len(augmented_sentences)):\n",
        "    bpd_data.append([label, augmented_sentences[j]])\n",
        "\n",
        "for i in range(len(schizo_data)):\n",
        "  sentence = schizo_data[0][1]\n",
        "  label = schizo_data[0][0]\n",
        "  augmented_sentences = eda.eda(sentence)\n",
        "  for j in range(len(augmented_sentences)):\n",
        "    schizo_data.append([label, augmented_sentences[j]])\n",
        "\n",
        "for i in range(len(dep_data)):\n",
        "  sentence = dep_data[0][1]\n",
        "  label = dep_data[0][0]\n",
        "  augmented_sentences = eda.eda(sentence)\n",
        "  for j in range(len(augmented_sentences)):\n",
        "    dep_data.append([label, augmented_sentences[j]])\n",
        "\n",
        "for i in range(len(men_data)):\n",
        "  sentence = men_data[0][1]\n",
        "  label = men_data[0][0]\n",
        "  augmented_sentences = eda.eda(sentence)\n",
        "  for j in range(len(augmented_sentences)):\n",
        "    men_data.append([label, augmented_sentences[j]])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdZ5udabrsOC"
      },
      "source": [
        "import random\n",
        "\n",
        "def getRandNumber(min, max, unallowed):\n",
        "  num = unallowed\n",
        "  while num == unallowed:\n",
        "    num = random.randint(min, max)\n",
        "  return num\n",
        "\n",
        "arrays = [anxiety_data, autism_data, bipolar_data, bpd_data, schizo_data, dep_data, men_data]\n",
        "\n",
        "labelled_data = []\n",
        "target_category = 5\n",
        "\n",
        "N = len(arrays[target_category])\n",
        "array = arrays[target_category]\n",
        "for i in range(N):\n",
        "    labelled_data.append([array[i],1])\n",
        "\n",
        "for i in range(N):\n",
        "    num = getRandNumber(0, len(arrays)-1, target_category)\n",
        "    array = arrays[num]\n",
        "    index = random.randint(0, len(array)-1)\n",
        "    labelled_data.append([array[index],0])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwgX7gNxsACk",
        "outputId": "1d6867d4-05a7-427b-c0e3-6a3c53297891"
      },
      "source": [
        "random.shuffle(labelled_data)\n",
        "print(labelled_data[0][1], labelled_data[5][1], labelled_data[200][1], labelled_data[500][1])\n",
        "\n",
        "N = len(labelled_data)\n",
        "print('Length: ', N)\n",
        "\n",
        "train_percent = 0.6\n",
        "dev_percent = 0.2\n",
        "test_percent = 0.2\n",
        "\n",
        "x_train_data = labelled_data[:int(train_percent*N)]\n",
        "x_dev_data = labelled_data[int(train_percent*N):int((train_percent+dev_percent)*N)]\n",
        "x_test_data = labelled_data[int((train_percent+dev_percent)*N):int((train_percent+dev_percent+test_percent)*N)]\n",
        "\n",
        "assert len(x_dev_data) == len(x_test_data) or len(x_test_data) + 1 or len(x_test_data) -1\n",
        "assert len(x_dev_data) + len(x_test_data) + len(x_train_data) == N"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 1 1 1\n",
            "Length:  169672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPBuizwOsw65",
        "outputId": "7b83786e-c457-4cb7-a8ac-16cd8fc3cd4d"
      },
      "source": [
        "x_train_int = []\n",
        "x_train_mask = []\n",
        "x_train_labels = []\n",
        "\n",
        "x_dev_int = []\n",
        "x_dev_mask = []\n",
        "x_dev_labels = []\n",
        "\n",
        "x_test_int = []\n",
        "x_test_mask = []\n",
        "x_test_labels = []\n",
        "\n",
        "for i in (range(len(x_train_data))):\n",
        "  data = x_train_data[i]\n",
        "  sentence = data[0][1]\n",
        "  x_train_labels.append(data[1])\n",
        "  ids,masks,segments = tokenize(sentence, tokenizer, pad_to_max_length=True)\n",
        "  x_train_int.append(ids)\n",
        "  x_train_mask.append(masks)\n",
        "\n",
        "for i in (range(len(x_dev_data))):\n",
        "  data = x_dev_data[i]\n",
        "  sentence = data[0][1]\n",
        "  x_dev_labels.append(data[1])\n",
        "  ids,masks,segments = tokenize(sentence, tokenizer, pad_to_max_length=True)\n",
        "  x_dev_int.append(ids)\n",
        "  x_dev_mask.append(masks)\n",
        "\n",
        "for i in (range(len(x_test_data))):\n",
        "  data = x_test_data[i]\n",
        "  sentence = data[0][1]\n",
        "  x_test_labels.append(data[1])\n",
        "  ids,masks,segments = tokenize(sentence, tokenizer, pad_to_max_length=True)\n",
        "  x_test_int.append(ids)\n",
        "  x_test_mask.append(masks)  \n",
        "\n",
        "# If use the previous tokenize function, you can get a print result like:\n",
        "assert len(x_train_int) == len(x_train_data)\n",
        "assert len(x_train_mask) == len(x_train_data)\n",
        "\n",
        "assert len(x_dev_int) == len(x_dev_data)\n",
        "assert len(x_dev_mask) == len(x_dev_data)\n",
        "\n",
        "assert len(x_test_int) == len(x_test_data)\n",
        "assert len(x_test_mask) == len(x_test_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWWUSD_wyA7a",
        "outputId": "7b781310-f320-4aba-f45c-7bcfbd224fbd"
      },
      "source": [
        "print(\"x_dev_int[0]:\")\n",
        "print(x_dev_int[0])\n",
        "print(\"x_dev_mask[0]:\")\n",
        "print(x_dev_mask[0])\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_dev_int[0]:\n",
            "[    0   118   236     7  2254  4158    19    82    53   939 17672   939\n",
            "    95 33976  2254    97  9379   118  2902 12467 21183  2379   358  1607\n",
            "  2653   101    10  6976     7   162     5  1690 26749   631    16   939\n",
            "  2694  5489  7223   236     7    28   441     7  8366   676  4158    19\n",
            "    82    53   939 17672   358   183   939 32592    53    63    98 29583\n",
            "     8   939   393   619   143  2789    50    55  2677   225  3804   939\n",
            "  4443    47   115   194    11   127  1291    19 14051  4356  1686     7\n",
            "   939   619   101    10  2125     9 15328   142   190   600   939   236\n",
            "     7   101   592  3258   939    95 17672     8    14  5745   939   283\n",
            "   160    25   182 13258   939   283   160    25  9888   939   283   160\n",
            "    25    41 30603    50    41  8446    53     2]\n",
            "x_dev_mask[0]:\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHKsIpAQ1ceN",
        "outputId": "072d2cc6-12db-4edd-f852-d776942a9488"
      },
      "source": [
        "def int2onehot(dataset):\n",
        "  y = []\n",
        "  for example in dataset:\n",
        "    if example:\n",
        "      y.append(np.array([0,1]))\n",
        "    else:\n",
        "      y.append(np.array([1,0]))\n",
        "  return np.array(y)\n",
        "\n",
        "\n",
        "x_train_labels = np.array(x_train_labels)\n",
        "x_dev_labels = np.array(x_dev_labels)\n",
        "x_test_labels = np.array(x_test_labels)\n",
        "y_train_onehot = int2onehot(x_train_labels)\n",
        "y_dev_onehot = int2onehot(x_dev_labels)\n",
        "y_test_onehot = int2onehot(x_test_labels)\n",
        "\n",
        "print(len(y_train_onehot), len(y_dev_onehot), len(y_test_onehot))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101803 33934 33935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2QwKTbA1jiI"
      },
      "source": [
        "x_train_int_np = np.array(x_train_int)\n",
        "x_train_mask_np = np.array(x_train_mask)\n",
        "x_dev_int_np = np.array(x_dev_int)\n",
        "x_dev_mask_np = np.array(x_dev_mask)\n",
        "x_test_int_np = np.array(x_test_int)\n",
        "x_test_mask_np = np.array(x_test_mask)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJOGiEpo2z22",
        "outputId": "9ee152f9-c202-4bc3-beb4-07ea5a9cb3db"
      },
      "source": [
        "from transformers import RobertaConfig, TFRobertaForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "ro_bert_a = 'roberta-base'\n",
        "\n",
        "config = RobertaConfig(num_labels=2)\n",
        "config.output_hidden_states = False\n",
        "\n",
        "def create_RoBERTaForSequenceClassification():\n",
        "  transformer_model = TFRobertaForSequenceClassification.from_pretrained(ro_bert_a)\n",
        "  input_ids = tf.keras.layers.Input(shape=(max_length,), name='input_token', dtype='int32')\n",
        "  input_masks_ids = tf.keras.layers.Input(shape=(max_length,), name='masked_token', dtype='int32')\n",
        "  X = transformer_model(input_ids, input_masks_ids)\n",
        "  return tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model on TPU:\n",
        "  with strategy.scope():\n",
        "    model = create_RoBERTaForSequenceClassification()\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model = create_RoBERTaForSequenceClassification()\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.79.138.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.79.138.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6998034de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6998034de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6998034de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f69ad780dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f69ad780dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f69ad780dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeA-3O-R34tZ",
        "outputId": "1cee7b5c-dc36-41c3-e784-aca201447750"
      },
      "source": [
        "model.summary() "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masked_token (InputLayer)       [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_for_sequence_classif TFSequenceClassifier 124647170   input_token[0][0]                \n",
            "                                                                 masked_token[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 124,647,170\n",
            "Trainable params: 124,647,170\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttI_D-q34JWt",
        "outputId": "348ef8bd-da73-463e-de5c-b77f2f4c4f72"
      },
      "source": [
        "history = model.fit([x_train_int_np,x_train_mask_np],\n",
        "                    y_train_onehot,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_mask_np], y_dev_onehot),\n",
        "                    verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "199/199 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.8498WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r199/199 [==============================] - 241s 764ms/step - loss: 0.4850 - accuracy: 0.8501 - val_loss: 0.1026 - val_accuracy: 0.9592\n",
            "Epoch 2/5\n",
            "199/199 [==============================] - 81s 405ms/step - loss: 0.1177 - accuracy: 0.9567 - val_loss: 0.1432 - val_accuracy: 0.9630\n",
            "Epoch 3/5\n",
            "199/199 [==============================] - 81s 405ms/step - loss: 0.1212 - accuracy: 0.9584 - val_loss: 0.1717 - val_accuracy: 0.8984\n",
            "Epoch 4/5\n",
            "199/199 [==============================] - 81s 406ms/step - loss: 0.1609 - accuracy: 0.9324 - val_loss: 0.1067 - val_accuracy: 0.9572\n",
            "Epoch 5/5\n",
            "199/199 [==============================] - 81s 405ms/step - loss: 0.1155 - accuracy: 0.9572 - val_loss: 0.1291 - val_accuracy: 0.9594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "371ZW6gmX2Gj",
        "outputId": "af5a26e8-5d5b-4b66-a83a-fe71e54270bc"
      },
      "source": [
        "results = model.evaluate([x_test_int_np,x_test_mask_np], y_test_onehot)\n",
        "print(results)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1061/1061 [==============================] - 38s 31ms/step - loss: 0.1248 - accuracy: 0.9600\n",
            "[0.12482868880033493, 0.9599823355674744]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhOld_C6iDj5",
        "outputId": "3cef6b75-5909-4e40-9606-b36bd030eee6"
      },
      "source": [
        "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
        "    def call(self, x, mask=None):\n",
        "        if mask != None:\n",
        "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
        "        else:\n",
        "            return super().call(x)\n",
        "\n",
        "from transformers import TFRobertaForSequenceClassification, TFRobertaModel\n",
        "\n",
        "def get_BERT_layer():\n",
        "  ro_bert_a = 'roberta-base'\n",
        "  config = RobertaConfig(dropout=0.2, attention_dropout=0.2)\n",
        "  config.output_hidden_states = False\n",
        "  return TFRobertaModel.from_pretrained(ro_bert_a)\n",
        "\n",
        "hdepth=16\n",
        "MAX_SEQUENCE_LENGTH = 128\n",
        "EMBED_SIZE=100\n",
        "\n",
        "def create_bag_of_words_BERT():\n",
        "  input_ids_in = tf.keras.layers.Input(shape=(max_length,), name='input_token', dtype='int32')\n",
        "  input_masks_in = tf.keras.layers.Input(shape=(max_length,), name='masked_token', dtype='int32') \n",
        "\n",
        "  bert_embeddings = get_BERT_layer()\n",
        "  embedded_sent = bert_embeddings(input_ids_in, attention_mask=input_masks_in)[0]\n",
        "\n",
        "  pooled_sent=GlobalAveragePooling1DMasked()(embedded_sent)\n",
        "  hidden_output=Dense(hdepth,input_shape=(MAX_SEQUENCE_LENGTH,EMBED_SIZE),activation='sigmoid',kernel_initializer='glorot_uniform')(pooled_sent) # Sigmoid\n",
        "  label=Dense(1,input_shape=(hdepth,),activation='sigmoid',kernel_initializer='glorot_uniform')(hidden_output)\n",
        "  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model\n",
        "  with strategy.scope():\n",
        "    model2 = create_bag_of_words_BERT()\n",
        "    optimizer2 = tf.keras.optimizers.Adam(lr=5e-5)\n",
        "    model2.compile(optimizer=optimizer2, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model2 = create_bag_of_words_BERT()\n",
        "  model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary() "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.79.138.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.79.138.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.79.138.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.79.138.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"Model2_BERT\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masked_token (InputLayer)       [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_token[0][0]                \n",
            "                                                                 masked_token[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_masked (None, 768)          0           tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 16)           12304       global_average_pooling1d_masked[0\n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            17          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 124,657,953\n",
            "Trainable params: 124,657,953\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doFVSas2iGxb",
        "outputId": "af2e3036-5485-4b27-ad51-cf65feec6f8c"
      },
      "source": [
        "history = model2.fit([x_train_int_np,x_train_mask_np],\n",
        "                    x_train_labels,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_mask_np], x_dev_labels),\n",
        "                    verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "199/199 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.9201WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r199/199 [==============================] - 238s 757ms/step - loss: 0.2431 - accuracy: 0.9202 - val_loss: 0.1551 - val_accuracy: 0.9630\n",
            "Epoch 2/5\n",
            "199/199 [==============================] - 80s 404ms/step - loss: 0.1460 - accuracy: 0.9689 - val_loss: 0.1487 - val_accuracy: 0.9652\n",
            "Epoch 3/5\n",
            "199/199 [==============================] - 81s 405ms/step - loss: 0.1290 - accuracy: 0.9761 - val_loss: 0.1493 - val_accuracy: 0.9641\n",
            "Epoch 4/5\n",
            "199/199 [==============================] - 81s 405ms/step - loss: 0.1126 - accuracy: 0.9828 - val_loss: 0.1494 - val_accuracy: 0.9638\n",
            "Epoch 5/5\n",
            "199/199 [==============================] - 81s 405ms/step - loss: 0.1016 - accuracy: 0.9869 - val_loss: 0.1459 - val_accuracy: 0.9639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXpcRO9DkGQD",
        "outputId": "cd069c8f-de41-4c38-a549-c23c5e0a9aac"
      },
      "source": [
        "results = model2.evaluate([x_test_int_np,x_test_mask_np], x_test_labels)\n",
        "print(results)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1061/1061 [==============================] - 37s 31ms/step - loss: 0.1451 - accuracy: 0.9643\n",
            "[0.14505493640899658, 0.9642552137374878]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXOeh-Zqj4zQ",
        "outputId": "3864bc53-7d21-4643-e207-e18189ead054"
      },
      "source": [
        "# your code goes here\n",
        "\n",
        "def get_BERT_layer():\n",
        "  ro_bert_a = 'roberta-base'\n",
        "  config = RobertaConfig(dropout=0.2, attention_dropout=0.2)\n",
        "  config.output_hidden_states = False\n",
        "  return TFRobertaModel.from_pretrained(ro_bert_a)\n",
        "  \n",
        "def create_CNN_BERT():\n",
        "  input_ids_in = tf.keras.layers.Input(shape=(max_length,), name='input_token', dtype='int32')\n",
        "  input_masks_in = tf.keras.layers.Input(shape=(max_length,), name='masked_token', dtype='int32') \n",
        "\n",
        "  bert_embeddings = get_BERT_layer()\n",
        "  embedded_sent = bert_embeddings(input_ids_in, attention_mask=input_masks_in)[0]\n",
        "  conv_vent = Conv1D(kernel_size=3, filters = 800)(embedded_sent)\n",
        "\n",
        "  pooled_sent=GlobalAveragePooling1DMasked()(conv_vent)\n",
        "  hidden_output=Dense(hdepth,input_shape=(MAX_SEQUENCE_LENGTH,EMBED_SIZE),activation='sigmoid',kernel_initializer='glorot_uniform')(pooled_sent) # Sigmoid\n",
        "  label=Dense(1,input_shape=(hdepth,),activation='sigmoid',kernel_initializer='glorot_uniform')(hidden_output)\n",
        "  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model\n",
        "  with strategy.scope():\n",
        "    model3 = create_CNN_BERT()\n",
        "    optimizer3 = tf.keras.optimizers.Adam(lr=5e-5)\n",
        "    model3.compile(optimizer=optimizer3, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model3 = create_CNN_BERT()\n",
        "  model3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.summary() "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.79.138.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.79.138.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.79.138.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.79.138.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"Model2_BERT\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masked_token (InputLayer)       [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model_1 (TFRobertaMo TFBaseModelOutputWit 124645632   input_token[0][0]                \n",
            "                                                                 masked_token[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 126, 800)     1844000     tf_roberta_model_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_masked (None, 800)          0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           12816       global_average_pooling1d_masked_1\n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            17          dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 126,502,465\n",
            "Trainable params: 126,502,465\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1giw7LSkC8F",
        "outputId": "5553c7e9-34d1-48cf-826c-6ba408f13afa"
      },
      "source": [
        "history = model3.fit([x_train_int_np,x_train_mask_np],\n",
        "                    x_train_labels,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_mask_np], x_dev_labels),\n",
        "                    verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "199/199 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9244WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r199/199 [==============================] - 242s 772ms/step - loss: 0.2440 - accuracy: 0.9245 - val_loss: 0.1657 - val_accuracy: 0.9650\n",
            "Epoch 2/5\n",
            "199/199 [==============================] - 82s 411ms/step - loss: 0.1566 - accuracy: 0.9690 - val_loss: 0.1601 - val_accuracy: 0.9653\n",
            "Epoch 3/5\n",
            "199/199 [==============================] - 82s 412ms/step - loss: 0.1389 - accuracy: 0.9761 - val_loss: 0.1543 - val_accuracy: 0.9659\n",
            "Epoch 4/5\n",
            "199/199 [==============================] - 82s 411ms/step - loss: 0.1214 - accuracy: 0.9829 - val_loss: 0.1512 - val_accuracy: 0.9663\n",
            "Epoch 5/5\n",
            "199/199 [==============================] - 82s 411ms/step - loss: 0.1090 - accuracy: 0.9864 - val_loss: 0.1521 - val_accuracy: 0.9655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJNJvwfGnyj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a54d2c90-91c6-4613-abc6-9dfe70d24221"
      },
      "source": [
        "results = model3.evaluate([x_test_int_np,x_test_mask_np], x_test_labels)\n",
        "print(results)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1061/1061 [==============================] - 38s 31ms/step - loss: 0.1507 - accuracy: 0.9656\n",
            "[0.15074880421161652, 0.9655812978744507]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2Tn60FznT0a",
        "outputId": "194db7da-5133-4113-e925-7c04a8675de8"
      },
      "source": [
        "# your code goes here\n",
        "\n",
        "def get_BERT_layer():\n",
        "  ro_bert_a = 'roberta-base'\n",
        "  config = RobertaConfig(dropout=0.2, attention_dropout=0.2)\n",
        "  config.output_hidden_states = False\n",
        "  return TFRobertaModel.from_pretrained(ro_bert_a)\n",
        "\n",
        "  \n",
        "def create_LSTM_BERT():\n",
        "  input_ids_in = tf.keras.layers.Input(shape=(max_length,), name='input_token', dtype='int32')\n",
        "  input_masks_in = tf.keras.layers.Input(shape=(max_length,), name='masked_token', dtype='int32') \n",
        "\n",
        "  bert_embeddings = get_BERT_layer()\n",
        "  embedded_sent = bert_embeddings(input_ids_in, attention_mask=input_masks_in)[0]\n",
        "  LSTM_vent = LSTM(units = 50, name='LSTM')(embedded_sent)\n",
        "\n",
        "  #pooled_sent=GlobalAveragePooling1DMasked()(LSTM_vent)\n",
        "  hidden_output=Dense(hdepth,input_shape=(MAX_SEQUENCE_LENGTH,EMBED_SIZE),activation='sigmoid',kernel_initializer='glorot_uniform')(LSTM_vent) # Sigmoid\n",
        "  label=Dense(1,input_shape=(hdepth,),activation='sigmoid',kernel_initializer='glorot_uniform')(hidden_output)\n",
        "  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model\n",
        "  with strategy.scope():\n",
        "    model4 = create_LSTM_BERT()\n",
        "    optimizer4 = tf.keras.optimizers.Adam(lr=5e-5)\n",
        "    model4.compile(optimizer=optimizer4, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model4 = create_LSTM_BERT()\n",
        "  model4.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model4.summary() "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.79.138.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.79.138.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.79.138.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.79.138.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"Model2_BERT\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masked_token (InputLayer)       [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model_2 (TFRobertaMo TFBaseModelOutputWit 124645632   input_token[0][0]                \n",
            "                                                                 masked_token[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "LSTM (LSTM)                     (None, 50)           163800      tf_roberta_model_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           816         LSTM[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            17          dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 124,810,265\n",
            "Trainable params: 124,810,265\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acq8JliCnvEV",
        "outputId": "4eb69cbf-24c1-4a9a-cf88-cc342a3020a2"
      },
      "source": [
        "history = model4.fit([x_train_int_np,x_train_mask_np],\n",
        "                    x_train_labels,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_mask_np], x_dev_labels),\n",
        "                    verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "199/199 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8744WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r199/199 [==============================] - 253s 825ms/step - loss: 0.3826 - accuracy: 0.8747 - val_loss: 0.2533 - val_accuracy: 0.9623\n",
            "Epoch 2/5\n",
            "199/199 [==============================] - 93s 470ms/step - loss: 0.2414 - accuracy: 0.9640 - val_loss: 0.2270 - val_accuracy: 0.9630\n",
            "Epoch 3/5\n",
            "199/199 [==============================] - 93s 469ms/step - loss: 0.2088 - accuracy: 0.9694 - val_loss: 0.2080 - val_accuracy: 0.9633\n",
            "Epoch 4/5\n",
            "199/199 [==============================] - 93s 469ms/step - loss: 0.1898 - accuracy: 0.9701 - val_loss: 0.1966 - val_accuracy: 0.9583\n",
            "Epoch 5/5\n",
            "199/199 [==============================] - 93s 469ms/step - loss: 0.1676 - accuracy: 0.9753 - val_loss: 0.1835 - val_accuracy: 0.9654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WZmQRx2n0CI",
        "outputId": "e0f406fa-6b4c-4ef9-801f-53d4354202f8"
      },
      "source": [
        "results = model4.evaluate([x_test_int_np,x_test_mask_np], x_test_labels)\n",
        "print(results)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1061/1061 [==============================] - 39s 32ms/step - loss: 0.1840 - accuracy: 0.9646\n",
            "[0.18404945731163025, 0.9645793437957764]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}